{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: Dio.netty.tryReflectionSetAccessible\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/06/21 11:36:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from spark_utils import get_spark_session\n",
    "\n",
    "spark = get_spark_session()\n",
    "train_data = spark.read.parquet('data_transformed/amex-default-prediction/train_data_aggregated')\n",
    "train_labels = spark.read.parquet('data/amex-default-prediction/train_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 423 ms, sys: 92.1 ms, total: 515 ms\n",
      "Wall time: 22.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from format_data import CATEGORICAL_VARIABLES\n",
    "from encoder import CategoricalToIntegerEncoders\n",
    "\n",
    "categorical_cols = []\n",
    "for c in CATEGORICAL_VARIABLES:\n",
    "    categorical_cols += [\n",
    "        # windowed features\n",
    "        c,\n",
    "        f'{c}_previous',\n",
    "        # aggregated_features\n",
    "        f'{c}_mode',\n",
    "    ]\n",
    "\n",
    "encs = CategoricalToIntegerEncoders(columns=categorical_cols).fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/21 11:37:18 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(feature_columns): 931\n",
      " S_2_days_since_previous, P_2, P_2_previous, D_39, D_39_previous, B_1, B_1_previous, B_2, B_2_previous, R_1, R_1_previous, S_3, S_3_previous, D_41, D_41_previous, B_3, B_3_previous, D_42, D_42_previous, D_43, D_43_previous, D_44, D_44_previous, B_4, B_4_previous, D_45, D_45_previous, B_5, B_5_previous, R_2, R_2_previous, D_46, D_46_previous, D_47, D_47_previous, D_48, D_48_previous, D_49, D_49_previous, B_6, B_6_previous, B_7, B_7_previous, B_8, B_8_previous, D_50, D_50_previous, D_51, D_51_previous, B_9, B_9_previous, R_3, R_3_previous, D_52, D_52_previous, P_3, P_3_previous, B_10, B_10_previous, D_53, D_53_previous, S_5, S_5_previous, B_11, B_11_previous, S_6, S_6_previous, D_54, D_54_previous, R_4, R_4_previous, S_7, S_7_previous, B_12, B_12_previous, S_8, S_8_previous, D_55, D_55_previous, D_56, D_56_previous, B_13, B_13_previous, R_5, R_5_previous, D_58, D_58_previous, S_9, S_9_previous, B_14, B_14_previous, D_59, D_59_previous, D_60, D_60_previous, D_61, D_61_previous, B_15, B_15_previous, S_11, S_11_previous, D_62, D_62_previous, D_65, D_65_previous, B_16, B_16_previous, B_17, B_17_previous, B_18, B_18_previous, B_19, B_19_previous, B_20, B_20_previous, S_12, S_12_previous, R_6, R_6_previous, S_13, S_13_previous, B_21, B_21_previous, D_69, D_69_previous, B_22, B_22_previous, D_70, D_70_previous, D_71, D_71_previous, D_72, D_72_previous, S_15, S_15_previous, B_23, B_23_previous, D_73, D_73_previous, P_4, P_4_previous, D_74, D_74_previous, D_75, D_75_previous, D_76, D_76_previous, B_24, B_24_previous, R_7, R_7_previous, D_77, D_77_previous, B_25, B_25_previous, B_26, B_26_previous, D_78, D_78_previous, D_79, D_79_previous, R_8, R_8_previous, R_9, R_9_previous, S_16, S_16_previous, D_80, D_80_previous, R_10, R_10_previous, R_11, R_11_previous, B_27, B_27_previous, D_81, D_81_previous, D_82, D_82_previous, S_17, S_17_previous, R_12, R_12_previous, B_28, B_28_previous, R_13, R_13_previous, D_83, D_83_previous, R_14, R_14_previous, R_15, R_15_previous, D_84, D_84_previous, R_16, R_16_previous, B_29, B_29_previous, S_18, S_18_previous, D_86, D_86_previous, D_87, D_87_previous, R_17, R_17_previous, R_18, R_18_previous, D_88, D_88_previous, B_31, B_31_previous, S_19, S_19_previous, R_19, R_19_previous, B_32, B_32_previous, S_20, S_20_previous, R_20, R_20_previous, R_21, R_21_previous, B_33, B_33_previous, D_89, D_89_previous, R_22, R_22_previous, R_23, R_23_previous, D_91, D_91_previous, D_92, D_92_previous, D_93, D_93_previous, D_94, D_94_previous, R_24, R_24_previous, R_25, R_25_previous, D_96, D_96_previous, S_22, S_22_previous, S_23, S_23_previous, S_24, S_24_previous, S_25, S_25_previous, S_26, S_26_previous, D_102, D_102_previous, D_103, D_103_previous, D_104, D_104_previous, D_105, D_105_previous, D_106, D_106_previous, D_107, D_107_previous, B_36, B_36_previous, B_37, B_37_previous, R_26, R_26_previous, R_27, R_27_previous, D_108, D_108_previous, D_109, D_109_previous, D_110, D_110_previous, D_111, D_111_previous, B_39, B_39_previous, D_112, D_112_previous, B_40, B_40_previous, S_27, S_27_previous, D_113, D_113_previous, D_115, D_115_previous, D_118, D_118_previous, D_119, D_119_previous, D_121, D_121_previous, D_122, D_122_previous, D_123, D_123_previous, D_124, D_124_previous, D_125, D_125_previous, D_127, D_127_previous, D_128, D_128_previous, D_129, D_129_previous, B_41, B_41_previous, B_42, B_42_previous, D_130, D_130_previous, D_131, D_131_previous, D_132, D_132_previous, D_133, D_133_previous, R_28, R_28_previous, D_134, D_134_previous, D_135, D_135_previous, D_136, D_136_previous, D_137, D_137_previous, D_138, D_138_previous, D_139, D_139_previous, D_140, D_140_previous, D_141, D_141_previous, D_142, D_142_previous, D_143, D_143_previous, D_144, D_144_previous, D_145, D_145_previous, num_statements, P_2_num_unique, P_2_max, P_2_mean, D_39_num_unique, D_39_max, D_39_mean, B_1_num_unique, B_1_max, B_1_mean, B_2_num_unique, B_2_max, B_2_mean, R_1_num_unique, R_1_max, R_1_mean, S_3_num_unique, S_3_max, S_3_mean, D_41_num_unique, D_41_max, D_41_mean, B_3_num_unique, B_3_max, B_3_mean, D_42_num_unique, D_42_max, D_42_mean, D_43_num_unique, D_43_max, D_43_mean, D_44_num_unique, D_44_max, D_44_mean, B_4_num_unique, B_4_max, B_4_mean, D_45_num_unique, D_45_max, D_45_mean, B_5_num_unique, B_5_max, B_5_mean, R_2_num_unique, R_2_max, R_2_mean, D_46_num_unique, D_46_max, D_46_mean, D_47_num_unique, D_47_max, D_47_mean, D_48_num_unique, D_48_max, D_48_mean, D_49_num_unique, D_49_max, D_49_mean, B_6_num_unique, B_6_max, B_6_mean, B_7_num_unique, B_7_max, B_7_mean, B_8_num_unique, B_8_max, B_8_mean, D_50_num_unique, D_50_max, D_50_mean, D_51_num_unique, D_51_max, D_51_mean, B_9_num_unique, B_9_max, B_9_mean, R_3_num_unique, R_3_max, R_3_mean, D_52_num_unique, D_52_max, D_52_mean, P_3_num_unique, P_3_max, P_3_mean, B_10_num_unique, B_10_max, B_10_mean, D_53_num_unique, D_53_max, D_53_mean, S_5_num_unique, S_5_max, S_5_mean, B_11_num_unique, B_11_max, B_11_mean, S_6_num_unique, S_6_max, S_6_mean, D_54_num_unique, D_54_max, D_54_mean, R_4_num_unique, R_4_max, R_4_mean, S_7_num_unique, S_7_max, S_7_mean, B_12_num_unique, B_12_max, B_12_mean, S_8_num_unique, S_8_max, S_8_mean, D_55_num_unique, D_55_max, D_55_mean, D_56_num_unique, D_56_max, D_56_mean, B_13_num_unique, B_13_max, B_13_mean, R_5_num_unique, R_5_max, R_5_mean, D_58_num_unique, D_58_max, D_58_mean, S_9_num_unique, S_9_max, S_9_mean, B_14_num_unique, B_14_max, B_14_mean, D_59_num_unique, D_59_max, D_59_mean, D_60_num_unique, D_60_max, D_60_mean, D_61_num_unique, D_61_max, D_61_mean, B_15_num_unique, B_15_max, B_15_mean, S_11_num_unique, S_11_max, S_11_mean, D_62_num_unique, D_62_max, D_62_mean, D_63_num_unique, D_64_num_unique, D_65_num_unique, D_65_max, D_65_mean, B_16_num_unique, B_16_max, B_16_mean, B_17_num_unique, B_17_max, B_17_mean, B_18_num_unique, B_18_max, B_18_mean, B_19_num_unique, B_19_max, B_19_mean, D_66_num_unique, B_20_num_unique, B_20_max, B_20_mean, D_68_num_unique, S_12_num_unique, S_12_max, S_12_mean, R_6_num_unique, R_6_max, R_6_mean, S_13_num_unique, S_13_max, S_13_mean, B_21_num_unique, B_21_max, B_21_mean, D_69_num_unique, D_69_max, D_69_mean, B_22_num_unique, B_22_max, B_22_mean, D_70_num_unique, D_70_max, D_70_mean, D_71_num_unique, D_71_max, D_71_mean, D_72_num_unique, D_72_max, D_72_mean, S_15_num_unique, S_15_max, S_15_mean, B_23_num_unique, B_23_max, B_23_mean, D_73_num_unique, D_73_max, D_73_mean, P_4_num_unique, P_4_max, P_4_mean, D_74_num_unique, D_74_max, D_74_mean, D_75_num_unique, D_75_max, D_75_mean, D_76_num_unique, D_76_max, D_76_mean, B_24_num_unique, B_24_max, B_24_mean, R_7_num_unique, R_7_max, R_7_mean, D_77_num_unique, D_77_max, D_77_mean, B_25_num_unique, B_25_max, B_25_mean, B_26_num_unique, B_26_max, B_26_mean, D_78_num_unique, D_78_max, D_78_mean, D_79_num_unique, D_79_max, D_79_mean, R_8_num_unique, R_8_max, R_8_mean, R_9_num_unique, R_9_max, R_9_mean, S_16_num_unique, S_16_max, S_16_mean, D_80_num_unique, D_80_max, D_80_mean, R_10_num_unique, R_10_max, R_10_mean, R_11_num_unique, R_11_max, R_11_mean, B_27_num_unique, B_27_max, B_27_mean, D_81_num_unique, D_81_max, D_81_mean, D_82_num_unique, D_82_max, D_82_mean, S_17_num_unique, S_17_max, S_17_mean, R_12_num_unique, R_12_max, R_12_mean, B_28_num_unique, B_28_max, B_28_mean, R_13_num_unique, R_13_max, R_13_mean, D_83_num_unique, D_83_max, D_83_mean, R_14_num_unique, R_14_max, R_14_mean, R_15_num_unique, R_15_max, R_15_mean, D_84_num_unique, D_84_max, D_84_mean, R_16_num_unique, R_16_max, R_16_mean, B_29_num_unique, B_29_max, B_29_mean, B_30_num_unique, S_18_num_unique, S_18_max, S_18_mean, D_86_num_unique, D_86_max, D_86_mean, D_87_num_unique, D_87_max, D_87_mean, R_17_num_unique, R_17_max, R_17_mean, R_18_num_unique, R_18_max, R_18_mean, D_88_num_unique, D_88_max, D_88_mean, B_31_num_unique, B_31_max, B_31_mean, S_19_num_unique, S_19_max, S_19_mean, R_19_num_unique, R_19_max, R_19_mean, B_32_num_unique, B_32_max, B_32_mean, S_20_num_unique, S_20_max, S_20_mean, R_20_num_unique, R_20_max, R_20_mean, R_21_num_unique, R_21_max, R_21_mean, B_33_num_unique, B_33_max, B_33_mean, D_89_num_unique, D_89_max, D_89_mean, R_22_num_unique, R_22_max, R_22_mean, R_23_num_unique, R_23_max, R_23_mean, D_91_num_unique, D_91_max, D_91_mean, D_92_num_unique, D_92_max, D_92_mean, D_93_num_unique, D_93_max, D_93_mean, D_94_num_unique, D_94_max, D_94_mean, R_24_num_unique, R_24_max, R_24_mean, R_25_num_unique, R_25_max, R_25_mean, D_96_num_unique, D_96_max, D_96_mean, S_22_num_unique, S_22_max, S_22_mean, S_23_num_unique, S_23_max, S_23_mean, S_24_num_unique, S_24_max, S_24_mean, S_25_num_unique, S_25_max, S_25_mean, S_26_num_unique, S_26_max, S_26_mean, D_102_num_unique, D_102_max, D_102_mean, D_103_num_unique, D_103_max, D_103_mean, D_104_num_unique, D_104_max, D_104_mean, D_105_num_unique, D_105_max, D_105_mean, D_106_num_unique, D_106_max, D_106_mean, D_107_num_unique, D_107_max, D_107_mean, B_36_num_unique, B_36_max, B_36_mean, B_37_num_unique, B_37_max, B_37_mean, R_26_num_unique, R_26_max, R_26_mean, R_27_num_unique, R_27_max, R_27_mean, B_38_num_unique, D_108_num_unique, D_108_max, D_108_mean, D_109_num_unique, D_109_max, D_109_mean, D_110_num_unique, D_110_max, D_110_mean, D_111_num_unique, D_111_max, D_111_mean, B_39_num_unique, B_39_max, B_39_mean, D_112_num_unique, D_112_max, D_112_mean, B_40_num_unique, B_40_max, B_40_mean, S_27_num_unique, S_27_max, S_27_mean, D_113_num_unique, D_113_max, D_113_mean, D_114_num_unique, D_115_num_unique, D_115_max, D_115_mean, D_116_num_unique, D_117_num_unique, D_118_num_unique, D_118_max, D_118_mean, D_119_num_unique, D_119_max, D_119_mean, D_120_num_unique, D_121_num_unique, D_121_max, D_121_mean, D_122_num_unique, D_122_max, D_122_mean, D_123_num_unique, D_123_max, D_123_mean, D_124_num_unique, D_124_max, D_124_mean, D_125_num_unique, D_125_max, D_125_mean, D_126_num_unique, D_127_num_unique, D_127_max, D_127_mean, D_128_num_unique, D_128_max, D_128_mean, D_129_num_unique, D_129_max, D_129_mean, B_41_num_unique, B_41_max, B_41_mean, B_42_num_unique, B_42_max, B_42_mean, D_130_num_unique, D_130_max, D_130_mean, D_131_num_unique, D_131_max, D_131_mean, D_132_num_unique, D_132_max, D_132_mean, D_133_num_unique, D_133_max, D_133_mean, R_28_num_unique, R_28_max, R_28_mean, D_134_num_unique, D_134_max, D_134_mean, D_135_num_unique, D_135_max, D_135_mean, D_136_num_unique, D_136_max, D_136_mean, D_137_num_unique, D_137_max, D_137_mean, D_138_num_unique, D_138_max, D_138_mean, D_139_num_unique, D_139_max, D_139_mean, D_140_num_unique, D_140_max, D_140_mean, D_141_num_unique, D_141_max, D_141_mean, D_142_num_unique, D_142_max, D_142_mean, D_143_num_unique, D_143_max, D_143_mean, D_144_num_unique, D_144_max, D_144_mean, D_145_num_unique, D_145_max, D_145_mean, B_30_CategoricalToIntegerEncoder, B_30_previous_CategoricalToIntegerEncoder, B_30_mode_CategoricalToIntegerEncoder, B_38_CategoricalToIntegerEncoder, B_38_previous_CategoricalToIntegerEncoder, B_38_mode_CategoricalToIntegerEncoder, D_114_CategoricalToIntegerEncoder, D_114_previous_CategoricalToIntegerEncoder, D_114_mode_CategoricalToIntegerEncoder, D_116_CategoricalToIntegerEncoder, D_116_previous_CategoricalToIntegerEncoder, D_116_mode_CategoricalToIntegerEncoder, D_117_CategoricalToIntegerEncoder, D_117_previous_CategoricalToIntegerEncoder, D_117_mode_CategoricalToIntegerEncoder, D_120_CategoricalToIntegerEncoder, D_120_previous_CategoricalToIntegerEncoder, D_120_mode_CategoricalToIntegerEncoder, D_126_CategoricalToIntegerEncoder, D_126_previous_CategoricalToIntegerEncoder, D_126_mode_CategoricalToIntegerEncoder, D_63_CategoricalToIntegerEncoder, D_63_previous_CategoricalToIntegerEncoder, D_63_mode_CategoricalToIntegerEncoder, D_64_CategoricalToIntegerEncoder, D_64_previous_CategoricalToIntegerEncoder, D_64_mode_CategoricalToIntegerEncoder, D_66_CategoricalToIntegerEncoder, D_66_previous_CategoricalToIntegerEncoder, D_66_mode_CategoricalToIntegerEncoder, D_68_CategoricalToIntegerEncoder, D_68_previous_CategoricalToIntegerEncoder, D_68_mode_CategoricalToIntegerEncoder\n",
      "CPU times: user 2.02 s, sys: 1.53 s, total: 3.54 s\n",
      "Wall time: 45.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from format_data import TARGET_VARIABLE, DATE_VARIABLES, ID_VARIABLES\n",
    "\n",
    "# make train_pdf\n",
    "train_pdf = train_data.join(train_labels, on='customer_ID', how='inner')\n",
    "train_pdf = encs.transform(spark=spark, df=train_pdf).toPandas()\n",
    "\n",
    "non_feature_columns = [\n",
    "    TARGET_VARIABLE,\n",
    "    *ID_VARIABLES,\n",
    "    *DATE_VARIABLES.keys(),\n",
    "]\n",
    "feature_columns = [c for c in train_pdf.columns if c not in non_feature_columns]\n",
    "print(f'len(feature_columns): {len(feature_columns)}\\n', ', '.join(feature_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458913, 931)\n",
      "(array([0., 1.], dtype=float32), array([340085, 118828]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_fit = train_pdf[feature_columns].reset_index(drop=True).astype(float)\n",
    "print(X_fit.shape)\n",
    "\n",
    "y_fit = np.array(train_pdf[TARGET_VARIABLE])\n",
    "print(np.unique(y_fit, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(344184, 931) (114729, 931) (344184,) (114729,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_fit, y_fit) \n",
    "print(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id a4afb732fa744b81b8e3163f9af307b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/usr/local/lib/python3.8/dist-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.8/dist-packages/lightgbm/basic.py:2068: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['B_30_CategoricalToIntegerEncoder', 'B_30_mode_CategoricalToIntegerEncoder', 'B_30_previous_CategoricalToIntegerEncoder', 'B_38_CategoricalToIntegerEncoder', 'B_38_mode_CategoricalToIntegerEncoder', 'B_38_previous_CategoricalToIntegerEncoder', 'D_114_CategoricalToIntegerEncoder', 'D_114_mode_CategoricalToIntegerEncoder', 'D_114_previous_CategoricalToIntegerEncoder', 'D_116_CategoricalToIntegerEncoder', 'D_116_mode_CategoricalToIntegerEncoder', 'D_116_previous_CategoricalToIntegerEncoder', 'D_117_CategoricalToIntegerEncoder', 'D_117_mode_CategoricalToIntegerEncoder', 'D_117_previous_CategoricalToIntegerEncoder', 'D_120_CategoricalToIntegerEncoder', 'D_120_mode_CategoricalToIntegerEncoder', 'D_120_previous_CategoricalToIntegerEncoder', 'D_126_CategoricalToIntegerEncoder', 'D_126_mode_CategoricalToIntegerEncoder', 'D_126_previous_CategoricalToIntegerEncoder', 'D_63_CategoricalToIntegerEncoder', 'D_63_mode_CategoricalToIntegerEncoder', 'D_63_previous_CategoricalToIntegerEncoder', 'D_64_CategoricalToIntegerEncoder', 'D_64_mode_CategoricalToIntegerEncoder', 'D_64_previous_CategoricalToIntegerEncoder', 'D_66_CategoricalToIntegerEncoder', 'D_66_mode_CategoricalToIntegerEncoder', 'D_66_previous_CategoricalToIntegerEncoder', 'D_68_CategoricalToIntegerEncoder', 'D_68_mode_CategoricalToIntegerEncoder', 'D_68_previous_CategoricalToIntegerEncoder']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=200, num_boost_round=200 will be ignored. Current value: num_iterations=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.8/dist-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain's binary_logloss: 0.519178\ttrain's amex: 0.706113\ttrain's amex_gini: 0.869267\ttrain's amex_top4: 0.54296\tvalid's binary_logloss: 0.520279\tvalid's amex: 0.697641\tvalid's amex_gini: 0.865518\tvalid's amex_top4: 0.529764\n",
      "[2]\ttrain's binary_logloss: 0.478901\ttrain's amex: 0.722597\ttrain's amex_gini: 0.880396\ttrain's amex_top4: 0.564799\tvalid's binary_logloss: 0.480236\tvalid's amex: 0.712963\tvalid's amex_gini: 0.876376\tvalid's amex_top4: 0.54955\n",
      "[3]\ttrain's binary_logloss: 0.446547\ttrain's amex: 0.728289\ttrain's amex_gini: 0.883908\ttrain's amex_top4: 0.57267\tvalid's binary_logloss: 0.448012\tvalid's amex: 0.718757\tvalid's amex_gini: 0.879969\tvalid's amex_top4: 0.557545\n",
      "[4]\ttrain's binary_logloss: 0.419907\ttrain's amex: 0.732422\ttrain's amex_gini: 0.8872\ttrain's amex_top4: 0.577644\tvalid's binary_logloss: 0.421526\tvalid's amex: 0.724649\tvalid's amex_gini: 0.883019\tvalid's amex_top4: 0.566279\n",
      "[5]\ttrain's binary_logloss: 0.397446\ttrain's amex: 0.734754\ttrain's amex_gini: 0.889012\ttrain's amex_top4: 0.580496\tvalid's binary_logloss: 0.399242\tvalid's amex: 0.726301\tvalid's amex_gini: 0.884979\tvalid's amex_top4: 0.567623\n",
      "[6]\ttrain's binary_logloss: 0.378467\ttrain's amex: 0.736567\ttrain's amex_gini: 0.890223\ttrain's amex_top4: 0.58291\tvalid's binary_logloss: 0.38041\tvalid's amex: 0.729787\tvalid's amex_gini: 0.886105\tvalid's amex_top4: 0.573468\n",
      "[7]\ttrain's binary_logloss: 0.36191\ttrain's amex: 0.739681\ttrain's amex_gini: 0.89315\ttrain's amex_top4: 0.586212\tvalid's binary_logloss: 0.364062\tvalid's amex: 0.732192\tvalid's amex_gini: 0.889304\tvalid's amex_top4: 0.575081\n",
      "[8]\ttrain's binary_logloss: 0.347745\ttrain's amex: 0.740942\ttrain's amex_gini: 0.894089\ttrain's amex_top4: 0.587795\tvalid's binary_logloss: 0.349994\tvalid's amex: 0.733021\tvalid's amex_gini: 0.890323\tvalid's amex_top4: 0.575719\n",
      "[9]\ttrain's binary_logloss: 0.335294\ttrain's amex: 0.744148\ttrain's amex_gini: 0.896099\ttrain's amex_top4: 0.592196\tvalid's binary_logloss: 0.337667\tvalid's amex: 0.736633\tvalid's amex_gini: 0.892374\tvalid's amex_top4: 0.580892\n",
      "[10]\ttrain's binary_logloss: 0.324352\ttrain's amex: 0.7463\ttrain's amex_gini: 0.897215\ttrain's amex_top4: 0.595385\tvalid's binary_logloss: 0.326838\tvalid's amex: 0.738745\tvalid's amex_gini: 0.893507\tvalid's amex_top4: 0.583983\n",
      "[11]\ttrain's binary_logloss: 0.314651\ttrain's amex: 0.747355\ttrain's amex_gini: 0.898471\ttrain's amex_top4: 0.596238\tvalid's binary_logloss: 0.317348\tvalid's amex: 0.739173\tvalid's amex_gini: 0.894564\tvalid's amex_top4: 0.583781\n",
      "[12]\ttrain's binary_logloss: 0.306109\ttrain's amex: 0.749307\ttrain's amex_gini: 0.899635\ttrain's amex_top4: 0.598978\tvalid's binary_logloss: 0.308975\tvalid's amex: 0.74182\tvalid's amex_gini: 0.895692\tvalid's amex_top4: 0.587947\n",
      "[13]\ttrain's binary_logloss: 0.298555\ttrain's amex: 0.750856\ttrain's amex_gini: 0.900555\ttrain's amex_top4: 0.601157\tvalid's binary_logloss: 0.301556\tvalid's amex: 0.74234\tvalid's amex_gini: 0.896465\tvalid's amex_top4: 0.588216\n",
      "[14]\ttrain's binary_logloss: 0.291822\ttrain's amex: 0.752541\ttrain's amex_gini: 0.901366\ttrain's amex_top4: 0.603717\tvalid's binary_logloss: 0.294941\tvalid's amex: 0.744659\tvalid's amex_gini: 0.897273\tvalid's amex_top4: 0.592045\n",
      "[15]\ttrain's binary_logloss: 0.285867\ttrain's amex: 0.753778\ttrain's amex_gini: 0.902098\ttrain's amex_top4: 0.605457\tvalid's binary_logloss: 0.289136\tvalid's amex: 0.74689\tvalid's amex_gini: 0.897905\tvalid's amex_top4: 0.595875\n",
      "[16]\ttrain's binary_logloss: 0.280478\ttrain's amex: 0.755436\ttrain's amex_gini: 0.903046\ttrain's amex_top4: 0.607826\tvalid's binary_logloss: 0.283882\tvalid's amex: 0.7475\tvalid's amex_gini: 0.898655\tvalid's amex_top4: 0.596345\n",
      "[17]\ttrain's binary_logloss: 0.275601\ttrain's amex: 0.757166\ttrain's amex_gini: 0.903991\ttrain's amex_top4: 0.610341\tvalid's binary_logloss: 0.279173\tvalid's amex: 0.748679\tvalid's amex_gini: 0.899535\tvalid's amex_top4: 0.597823\n",
      "[18]\ttrain's binary_logloss: 0.271202\ttrain's amex: 0.758849\ttrain's amex_gini: 0.904841\ttrain's amex_top4: 0.612857\tvalid's binary_logloss: 0.274924\tvalid's amex: 0.750117\tvalid's amex_gini: 0.900396\tvalid's amex_top4: 0.599839\n",
      "[19]\ttrain's binary_logloss: 0.267323\ttrain's amex: 0.759532\ttrain's amex_gini: 0.905477\ttrain's amex_top4: 0.613586\tvalid's binary_logloss: 0.271226\tvalid's amex: 0.751209\tvalid's amex_gini: 0.900933\tvalid's amex_top4: 0.601485\n",
      "[20]\ttrain's binary_logloss: 0.263712\ttrain's amex: 0.760754\ttrain's amex_gini: 0.906496\ttrain's amex_top4: 0.615012\tvalid's binary_logloss: 0.267778\tvalid's amex: 0.752456\tvalid's amex_gini: 0.901882\tvalid's amex_top4: 0.60303\n",
      "[21]\ttrain's binary_logloss: 0.260401\ttrain's amex: 0.762337\ttrain's amex_gini: 0.907147\ttrain's amex_top4: 0.617528\tvalid's binary_logloss: 0.264612\tvalid's amex: 0.753757\tvalid's amex_gini: 0.902436\tvalid's amex_top4: 0.605079\n",
      "[22]\ttrain's binary_logloss: 0.257516\ttrain's amex: 0.763535\ttrain's amex_gini: 0.907679\ttrain's amex_top4: 0.619391\tvalid's binary_logloss: 0.261845\tvalid's amex: 0.753898\tvalid's amex_gini: 0.902952\tvalid's amex_top4: 0.604844\n",
      "[23]\ttrain's binary_logloss: 0.254727\ttrain's amex: 0.764539\ttrain's amex_gini: 0.908283\ttrain's amex_top4: 0.620795\tvalid's binary_logloss: 0.259151\tvalid's amex: 0.755427\tvalid's amex_gini: 0.903591\tvalid's amex_top4: 0.607263\n",
      "[24]\ttrain's binary_logloss: 0.252294\ttrain's amex: 0.765475\ttrain's amex_gini: 0.908774\ttrain's amex_top4: 0.622176\tvalid's binary_logloss: 0.256833\tvalid's amex: 0.756265\tvalid's amex_gini: 0.904091\tvalid's amex_top4: 0.608439\n",
      "[25]\ttrain's binary_logloss: 0.25008\ttrain's amex: 0.766774\ttrain's amex_gini: 0.909362\ttrain's amex_top4: 0.624186\tvalid's binary_logloss: 0.254792\tvalid's amex: 0.756944\tvalid's amex_gini: 0.904541\tvalid's amex_top4: 0.609346\n",
      "[26]\ttrain's binary_logloss: 0.248028\ttrain's amex: 0.767513\ttrain's amex_gini: 0.909909\ttrain's amex_top4: 0.625118\tvalid's binary_logloss: 0.252836\tvalid's amex: 0.757895\tvalid's amex_gini: 0.905101\tvalid's amex_top4: 0.610689\n",
      "[27]\ttrain's binary_logloss: 0.246097\ttrain's amex: 0.768638\ttrain's amex_gini: 0.910475\ttrain's amex_top4: 0.626802\tvalid's binary_logloss: 0.251019\tvalid's amex: 0.759122\tvalid's amex_gini: 0.90564\tvalid's amex_top4: 0.612604\n",
      "[28]\ttrain's binary_logloss: 0.244368\ttrain's amex: 0.76985\ttrain's amex_gini: 0.910978\ttrain's amex_top4: 0.628722\tvalid's binary_logloss: 0.249435\tvalid's amex: 0.759455\tvalid's amex_gini: 0.906071\tvalid's amex_top4: 0.612839\n",
      "[29]\ttrain's binary_logloss: 0.242721\ttrain's amex: 0.770597\ttrain's amex_gini: 0.911507\ttrain's amex_top4: 0.629688\tvalid's binary_logloss: 0.247963\tvalid's amex: 0.7603\tvalid's amex_gini: 0.906518\tvalid's amex_top4: 0.614082\n",
      "[30]\ttrain's binary_logloss: 0.241121\ttrain's amex: 0.771494\ttrain's amex_gini: 0.912121\ttrain's amex_top4: 0.630867\tvalid's binary_logloss: 0.246499\tvalid's amex: 0.762012\tvalid's amex_gini: 0.907119\tvalid's amex_top4: 0.616904\n",
      "[31]\ttrain's binary_logloss: 0.239735\ttrain's amex: 0.772853\ttrain's amex_gini: 0.912616\ttrain's amex_top4: 0.63309\tvalid's binary_logloss: 0.245257\tvalid's amex: 0.76273\tvalid's amex_gini: 0.90748\tvalid's amex_top4: 0.617979\n",
      "[32]\ttrain's binary_logloss: 0.238459\ttrain's amex: 0.77347\ttrain's amex_gini: 0.91302\ttrain's amex_top4: 0.633921\tvalid's binary_logloss: 0.244081\tvalid's amex: 0.763767\tvalid's amex_gini: 0.907841\tvalid's amex_top4: 0.619692\n",
      "[33]\ttrain's binary_logloss: 0.237311\ttrain's amex: 0.774339\ttrain's amex_gini: 0.913365\ttrain's amex_top4: 0.635313\tvalid's binary_logloss: 0.243028\tvalid's amex: 0.764366\tvalid's amex_gini: 0.908166\tvalid's amex_top4: 0.620566\n",
      "[34]\ttrain's binary_logloss: 0.236157\ttrain's amex: 0.775523\ttrain's amex_gini: 0.91379\ttrain's amex_top4: 0.637256\tvalid's binary_logloss: 0.241967\tvalid's amex: 0.765265\tvalid's amex_gini: 0.908554\tvalid's amex_top4: 0.621977\n",
      "[35]\ttrain's binary_logloss: 0.235096\ttrain's amex: 0.776217\ttrain's amex_gini: 0.914268\ttrain's amex_top4: 0.638165\tvalid's binary_logloss: 0.241063\tvalid's amex: 0.765507\tvalid's amex_gini: 0.908971\tvalid's amex_top4: 0.622044\n",
      "[36]\ttrain's binary_logloss: 0.234132\ttrain's amex: 0.776983\ttrain's amex_gini: 0.914688\ttrain's amex_top4: 0.639277\tvalid's binary_logloss: 0.240203\tvalid's amex: 0.765622\tvalid's amex_gini: 0.909301\tvalid's amex_top4: 0.621943\n",
      "[37]\ttrain's binary_logloss: 0.233203\ttrain's amex: 0.777764\ttrain's amex_gini: 0.91505\ttrain's amex_top4: 0.640478\tvalid's binary_logloss: 0.239419\tvalid's amex: 0.765839\tvalid's amex_gini: 0.909566\tvalid's amex_top4: 0.622111\n",
      "[38]\ttrain's binary_logloss: 0.232317\ttrain's amex: 0.778344\ttrain's amex_gini: 0.915525\ttrain's amex_top4: 0.641163\tvalid's binary_logloss: 0.238703\tvalid's amex: 0.766989\tvalid's amex_gini: 0.909919\tvalid's amex_top4: 0.624059\n",
      "[39]\ttrain's binary_logloss: 0.231477\ttrain's amex: 0.779004\ttrain's amex_gini: 0.915902\ttrain's amex_top4: 0.642106\tvalid's binary_logloss: 0.237988\tvalid's amex: 0.767644\tvalid's amex_gini: 0.910221\tvalid's amex_top4: 0.625067\n",
      "[40]\ttrain's binary_logloss: 0.230671\ttrain's amex: 0.779558\ttrain's amex_gini: 0.916292\ttrain's amex_top4: 0.642825\tvalid's binary_logloss: 0.237318\tvalid's amex: 0.76804\tvalid's amex_gini: 0.910576\tvalid's amex_top4: 0.625504\n",
      "[41]\ttrain's binary_logloss: 0.22995\ttrain's amex: 0.7803\ttrain's amex_gini: 0.916641\ttrain's amex_top4: 0.643959\tvalid's binary_logloss: 0.236705\tvalid's amex: 0.768772\tvalid's amex_gini: 0.910898\tvalid's amex_top4: 0.626646\n",
      "[42]\ttrain's binary_logloss: 0.22929\ttrain's amex: 0.781005\ttrain's amex_gini: 0.916951\ttrain's amex_top4: 0.64506\tvalid's binary_logloss: 0.236179\tvalid's amex: 0.769297\tvalid's amex_gini: 0.911142\tvalid's amex_top4: 0.627452\n",
      "[43]\ttrain's binary_logloss: 0.228671\ttrain's amex: 0.78181\ttrain's amex_gini: 0.917292\ttrain's amex_top4: 0.646328\tvalid's binary_logloss: 0.235696\tvalid's amex: 0.769516\tvalid's amex_gini: 0.911378\tvalid's amex_top4: 0.627654\n",
      "[44]\ttrain's binary_logloss: 0.227987\ttrain's amex: 0.782464\ttrain's amex_gini: 0.917657\ttrain's amex_top4: 0.647272\tvalid's binary_logloss: 0.235176\tvalid's amex: 0.770115\tvalid's amex_gini: 0.911635\tvalid's amex_top4: 0.628594\n",
      "[45]\ttrain's binary_logloss: 0.227381\ttrain's amex: 0.783556\ttrain's amex_gini: 0.917989\ttrain's amex_top4: 0.649124\tvalid's binary_logloss: 0.234694\tvalid's amex: 0.770361\tvalid's amex_gini: 0.911892\tvalid's amex_top4: 0.62883\n",
      "[46]\ttrain's binary_logloss: 0.226787\ttrain's amex: 0.783978\ttrain's amex_gini: 0.918316\ttrain's amex_top4: 0.649641\tvalid's binary_logloss: 0.23422\tvalid's amex: 0.770637\tvalid's amex_gini: 0.912142\tvalid's amex_top4: 0.629132\n",
      "[47]\ttrain's binary_logloss: 0.226243\ttrain's amex: 0.784552\ttrain's amex_gini: 0.918621\ttrain's amex_top4: 0.650483\tvalid's binary_logloss: 0.233812\tvalid's amex: 0.770966\tvalid's amex_gini: 0.912364\tvalid's amex_top4: 0.629569\n",
      "[48]\ttrain's binary_logloss: 0.2257\ttrain's amex: 0.784777\ttrain's amex_gini: 0.918969\ttrain's amex_top4: 0.650584\tvalid's binary_logloss: 0.233472\tvalid's amex: 0.771611\tvalid's amex_gini: 0.912545\tvalid's amex_top4: 0.630677\n",
      "[49]\ttrain's binary_logloss: 0.225172\ttrain's amex: 0.785793\ttrain's amex_gini: 0.919261\ttrain's amex_top4: 0.652324\tvalid's binary_logloss: 0.233062\tvalid's amex: 0.772281\tvalid's amex_gini: 0.912776\tvalid's amex_top4: 0.631786\n",
      "[50]\ttrain's binary_logloss: 0.224679\ttrain's amex: 0.786077\ttrain's amex_gini: 0.919549\ttrain's amex_top4: 0.652605\tvalid's binary_logloss: 0.232659\tvalid's amex: 0.772607\tvalid's amex_gini: 0.913026\tvalid's amex_top4: 0.632189\n",
      "[51]\ttrain's binary_logloss: 0.224176\ttrain's amex: 0.786245\ttrain's amex_gini: 0.91984\ttrain's amex_top4: 0.65265\tvalid's binary_logloss: 0.232306\tvalid's amex: 0.773368\tvalid's amex_gini: 0.913203\tvalid's amex_top4: 0.633533\n",
      "[52]\ttrain's binary_logloss: 0.223723\ttrain's amex: 0.787085\ttrain's amex_gini: 0.920094\ttrain's amex_top4: 0.654076\tvalid's binary_logloss: 0.231978\tvalid's amex: 0.773173\tvalid's amex_gini: 0.913385\tvalid's amex_top4: 0.632962\n",
      "[53]\ttrain's binary_logloss: 0.223288\ttrain's amex: 0.787508\ttrain's amex_gini: 0.920368\ttrain's amex_top4: 0.654649\tvalid's binary_logloss: 0.231617\tvalid's amex: 0.773915\tvalid's amex_gini: 0.913625\tvalid's amex_top4: 0.634205\n",
      "[54]\ttrain's binary_logloss: 0.22281\ttrain's amex: 0.78779\ttrain's amex_gini: 0.920674\ttrain's amex_top4: 0.654907\tvalid's binary_logloss: 0.231228\tvalid's amex: 0.77406\tvalid's amex_gini: 0.913882\tvalid's amex_top4: 0.634238\n",
      "[55]\ttrain's binary_logloss: 0.222388\ttrain's amex: 0.788049\ttrain's amex_gini: 0.920933\ttrain's amex_top4: 0.655165\tvalid's binary_logloss: 0.230929\tvalid's amex: 0.774473\tvalid's amex_gini: 0.91407\tvalid's amex_top4: 0.634876\n",
      "[56]\ttrain's binary_logloss: 0.221962\ttrain's amex: 0.789035\ttrain's amex_gini: 0.921199\ttrain's amex_top4: 0.656872\tvalid's binary_logloss: 0.230644\tvalid's amex: 0.775046\tvalid's amex_gini: 0.914242\tvalid's amex_top4: 0.635851\n",
      "[57]\ttrain's binary_logloss: 0.221573\ttrain's amex: 0.789301\ttrain's amex_gini: 0.921449\ttrain's amex_top4: 0.657152\tvalid's binary_logloss: 0.230361\tvalid's amex: 0.775659\tvalid's amex_gini: 0.914426\tvalid's amex_top4: 0.636892\n",
      "[58]\ttrain's binary_logloss: 0.221195\ttrain's amex: 0.789608\ttrain's amex_gini: 0.921693\ttrain's amex_top4: 0.657523\tvalid's binary_logloss: 0.230096\tvalid's amex: 0.77556\tvalid's amex_gini: 0.914597\tvalid's amex_top4: 0.636522\n",
      "[59]\ttrain's binary_logloss: 0.220828\ttrain's amex: 0.790084\ttrain's amex_gini: 0.921926\ttrain's amex_top4: 0.658242\tvalid's binary_logloss: 0.229881\tvalid's amex: 0.775866\tvalid's amex_gini: 0.91474\tvalid's amex_top4: 0.636993\n",
      "[60]\ttrain's binary_logloss: 0.220489\ttrain's amex: 0.790609\ttrain's amex_gini: 0.922157\ttrain's amex_top4: 0.659061\tvalid's binary_logloss: 0.229682\tvalid's amex: 0.77588\tvalid's amex_gini: 0.914868\tvalid's amex_top4: 0.636892\n",
      "[61]\ttrain's binary_logloss: 0.220125\ttrain's amex: 0.790771\ttrain's amex_gini: 0.922379\ttrain's amex_top4: 0.659162\tvalid's binary_logloss: 0.229439\tvalid's amex: 0.775748\tvalid's amex_gini: 0.915008\tvalid's amex_top4: 0.636489\n",
      "[62]\ttrain's binary_logloss: 0.219807\ttrain's amex: 0.79171\ttrain's amex_gini: 0.922584\ttrain's amex_top4: 0.660835\tvalid's binary_logloss: 0.229227\tvalid's amex: 0.776186\tvalid's amex_gini: 0.915143\tvalid's amex_top4: 0.637228\n",
      "[63]\ttrain's binary_logloss: 0.21946\ttrain's amex: 0.791849\ttrain's amex_gini: 0.922796\ttrain's amex_top4: 0.660903\tvalid's binary_logloss: 0.229004\tvalid's amex: 0.776454\tvalid's amex_gini: 0.915276\tvalid's amex_top4: 0.637631\n",
      "[64]\ttrain's binary_logloss: 0.219136\ttrain's amex: 0.792294\ttrain's amex_gini: 0.923\ttrain's amex_top4: 0.661588\tvalid's binary_logloss: 0.228796\tvalid's amex: 0.776824\tvalid's amex_gini: 0.915412\tvalid's amex_top4: 0.638236\n",
      "[65]\ttrain's binary_logloss: 0.218782\ttrain's amex: 0.792498\ttrain's amex_gini: 0.923229\ttrain's amex_top4: 0.661767\tvalid's binary_logloss: 0.228557\tvalid's amex: 0.77732\tvalid's amex_gini: 0.915565\tvalid's amex_top4: 0.639076\n",
      "[66]\ttrain's binary_logloss: 0.218467\ttrain's amex: 0.792774\ttrain's amex_gini: 0.923433\ttrain's amex_top4: 0.662115\tvalid's binary_logloss: 0.228321\tvalid's amex: 0.777383\tvalid's amex_gini: 0.915724\tvalid's amex_top4: 0.639042\n",
      "[67]\ttrain's binary_logloss: 0.218149\ttrain's amex: 0.793226\ttrain's amex_gini: 0.923652\ttrain's amex_top4: 0.6628\tvalid's binary_logloss: 0.228121\tvalid's amex: 0.777386\tvalid's amex_gini: 0.915865\tvalid's amex_top4: 0.638908\n",
      "[68]\ttrain's binary_logloss: 0.217833\ttrain's amex: 0.793738\ttrain's amex_gini: 0.923866\ttrain's amex_top4: 0.663609\tvalid's binary_logloss: 0.22796\tvalid's amex: 0.778012\tvalid's amex_gini: 0.915975\tvalid's amex_top4: 0.64005\n",
      "[69]\ttrain's binary_logloss: 0.217521\ttrain's amex: 0.794292\ttrain's amex_gini: 0.924076\ttrain's amex_top4: 0.664507\tvalid's binary_logloss: 0.227819\tvalid's amex: 0.777791\tvalid's amex_gini: 0.91607\tvalid's amex_top4: 0.639512\n",
      "[70]\ttrain's binary_logloss: 0.217202\ttrain's amex: 0.794692\ttrain's amex_gini: 0.924283\ttrain's amex_top4: 0.665102\tvalid's binary_logloss: 0.227638\tvalid's amex: 0.778239\tvalid's amex_gini: 0.916194\tvalid's amex_top4: 0.640285\n",
      "[71]\ttrain's binary_logloss: 0.216905\ttrain's amex: 0.794829\ttrain's amex_gini: 0.924478\ttrain's amex_top4: 0.665181\tvalid's binary_logloss: 0.227422\tvalid's amex: 0.778481\tvalid's amex_gini: 0.91634\tvalid's amex_top4: 0.640621\n",
      "[72]\ttrain's binary_logloss: 0.216636\ttrain's amex: 0.79533\ttrain's amex_gini: 0.92466\ttrain's amex_top4: 0.666\tvalid's binary_logloss: 0.227272\tvalid's amex: 0.779019\tvalid's amex_gini: 0.916442\tvalid's amex_top4: 0.641595\n",
      "[73]\ttrain's binary_logloss: 0.216382\ttrain's amex: 0.795504\ttrain's amex_gini: 0.924828\ttrain's amex_top4: 0.66618\tvalid's binary_logloss: 0.227125\tvalid's amex: 0.778694\tvalid's amex_gini: 0.916532\tvalid's amex_top4: 0.640856\n",
      "[74]\ttrain's binary_logloss: 0.216083\ttrain's amex: 0.795894\ttrain's amex_gini: 0.925024\ttrain's amex_top4: 0.666764\tvalid's binary_logloss: 0.226922\tvalid's amex: 0.77947\tvalid's amex_gini: 0.916673\tvalid's amex_top4: 0.642267\n",
      "[75]\ttrain's binary_logloss: 0.215824\ttrain's amex: 0.796033\ttrain's amex_gini: 0.925201\ttrain's amex_top4: 0.666865\tvalid's binary_logloss: 0.22676\tvalid's amex: 0.779511\tvalid's amex_gini: 0.916789\tvalid's amex_top4: 0.642233\n",
      "[76]\ttrain's binary_logloss: 0.215534\ttrain's amex: 0.796641\ttrain's amex_gini: 0.925384\ttrain's amex_top4: 0.667898\tvalid's binary_logloss: 0.226584\tvalid's amex: 0.779938\tvalid's amex_gini: 0.916905\tvalid's amex_top4: 0.642972\n",
      "[77]\ttrain's binary_logloss: 0.215296\ttrain's amex: 0.79707\ttrain's amex_gini: 0.925546\ttrain's amex_top4: 0.668594\tvalid's binary_logloss: 0.226501\tvalid's amex: 0.779897\tvalid's amex_gini: 0.916955\tvalid's amex_top4: 0.642838\n",
      "[78]\ttrain's binary_logloss: 0.215019\ttrain's amex: 0.797365\ttrain's amex_gini: 0.925731\ttrain's amex_top4: 0.668998\tvalid's binary_logloss: 0.226344\tvalid's amex: 0.779747\tvalid's amex_gini: 0.91706\tvalid's amex_top4: 0.642435\n",
      "[79]\ttrain's binary_logloss: 0.214751\ttrain's amex: 0.797669\ttrain's amex_gini: 0.925914\ttrain's amex_top4: 0.669425\tvalid's binary_logloss: 0.226173\tvalid's amex: 0.780282\tvalid's amex_gini: 0.917188\tvalid's amex_top4: 0.643375\n",
      "[80]\ttrain's binary_logloss: 0.214503\ttrain's amex: 0.797634\ttrain's amex_gini: 0.926078\ttrain's amex_top4: 0.669189\tvalid's binary_logloss: 0.226055\tvalid's amex: 0.780155\tvalid's amex_gini: 0.917271\tvalid's amex_top4: 0.64304\n",
      "[81]\ttrain's binary_logloss: 0.214272\ttrain's amex: 0.798115\ttrain's amex_gini: 0.926233\ttrain's amex_top4: 0.669998\tvalid's binary_logloss: 0.225938\tvalid's amex: 0.780529\tvalid's amex_gini: 0.917347\tvalid's amex_top4: 0.643711\n",
      "[82]\ttrain's binary_logloss: 0.214024\ttrain's amex: 0.798414\ttrain's amex_gini: 0.926393\ttrain's amex_top4: 0.670436\tvalid's binary_logloss: 0.225818\tvalid's amex: 0.780705\tvalid's amex_gini: 0.917431\tvalid's amex_top4: 0.64398\n",
      "[83]\ttrain's binary_logloss: 0.21378\ttrain's amex: 0.798643\ttrain's amex_gini: 0.926558\ttrain's amex_top4: 0.670728\tvalid's binary_logloss: 0.225703\tvalid's amex: 0.780928\tvalid's amex_gini: 0.917507\tvalid's amex_top4: 0.64435\n",
      "[84]\ttrain's binary_logloss: 0.213531\ttrain's amex: 0.799201\ttrain's amex_gini: 0.926731\ttrain's amex_top4: 0.671671\tvalid's binary_logloss: 0.225576\tvalid's amex: 0.781107\tvalid's amex_gini: 0.917596\tvalid's amex_top4: 0.644618\n",
      "[85]\ttrain's binary_logloss: 0.213303\ttrain's amex: 0.799437\ttrain's amex_gini: 0.926889\ttrain's amex_top4: 0.671985\tvalid's binary_logloss: 0.225477\tvalid's amex: 0.781444\tvalid's amex_gini: 0.917664\tvalid's amex_top4: 0.645223\n",
      "[86]\ttrain's binary_logloss: 0.213024\ttrain's amex: 0.799724\ttrain's amex_gini: 0.927091\ttrain's amex_top4: 0.672356\tvalid's binary_logloss: 0.225344\tvalid's amex: 0.78201\tvalid's amex_gini: 0.917755\tvalid's amex_top4: 0.646264\n",
      "[87]\ttrain's binary_logloss: 0.21279\ttrain's amex: 0.800258\ttrain's amex_gini: 0.927251\ttrain's amex_top4: 0.673265\tvalid's binary_logloss: 0.225195\tvalid's amex: 0.781744\tvalid's amex_gini: 0.917862\tvalid's amex_top4: 0.645626\n",
      "[88]\ttrain's binary_logloss: 0.212556\ttrain's amex: 0.800512\ttrain's amex_gini: 0.927411\ttrain's amex_top4: 0.673613\tvalid's binary_logloss: 0.225098\tvalid's amex: 0.781843\tvalid's amex_gini: 0.917926\tvalid's amex_top4: 0.645761\n",
      "[89]\ttrain's binary_logloss: 0.212335\ttrain's amex: 0.800645\ttrain's amex_gini: 0.927565\ttrain's amex_top4: 0.673726\tvalid's binary_logloss: 0.225012\tvalid's amex: 0.78204\tvalid's amex_gini: 0.917983\tvalid's amex_top4: 0.646096\n",
      "[90]\ttrain's binary_logloss: 0.212098\ttrain's amex: 0.801001\ttrain's amex_gini: 0.927738\ttrain's amex_top4: 0.674265\tvalid's binary_logloss: 0.224912\tvalid's amex: 0.782261\tvalid's amex_gini: 0.918055\tvalid's amex_top4: 0.646466\n",
      "[91]\ttrain's binary_logloss: 0.211884\ttrain's amex: 0.801586\ttrain's amex_gini: 0.927886\ttrain's amex_top4: 0.675286\tvalid's binary_logloss: 0.224804\tvalid's amex: 0.782386\tvalid's amex_gini: 0.918139\tvalid's amex_top4: 0.646634\n",
      "[92]\ttrain's binary_logloss: 0.211687\ttrain's amex: 0.801849\ttrain's amex_gini: 0.928018\ttrain's amex_top4: 0.675679\tvalid's binary_logloss: 0.22472\tvalid's amex: 0.782514\tvalid's amex_gini: 0.918193\tvalid's amex_top4: 0.646836\n",
      "[93]\ttrain's binary_logloss: 0.211486\ttrain's amex: 0.802148\ttrain's amex_gini: 0.928167\ttrain's amex_top4: 0.676128\tvalid's binary_logloss: 0.224618\tvalid's amex: 0.782718\tvalid's amex_gini: 0.918265\tvalid's amex_top4: 0.647171\n",
      "[94]\ttrain's binary_logloss: 0.211266\ttrain's amex: 0.802201\ttrain's amex_gini: 0.928319\ttrain's amex_top4: 0.676084\tvalid's binary_logloss: 0.224579\tvalid's amex: 0.782816\tvalid's amex_gini: 0.918293\tvalid's amex_top4: 0.647339\n",
      "[95]\ttrain's binary_logloss: 0.211051\ttrain's amex: 0.802782\ttrain's amex_gini: 0.928459\ttrain's amex_top4: 0.677105\tvalid's binary_logloss: 0.224471\tvalid's amex: 0.783167\tvalid's amex_gini: 0.918357\tvalid's amex_top4: 0.647978\n",
      "[96]\ttrain's binary_logloss: 0.210857\ttrain's amex: 0.802884\ttrain's amex_gini: 0.928585\ttrain's amex_top4: 0.677184\tvalid's binary_logloss: 0.224419\tvalid's amex: 0.783401\tvalid's amex_gini: 0.918388\tvalid's amex_top4: 0.648414\n",
      "[97]\ttrain's binary_logloss: 0.210657\ttrain's amex: 0.803172\ttrain's amex_gini: 0.928711\ttrain's amex_top4: 0.677633\tvalid's binary_logloss: 0.224333\tvalid's amex: 0.783128\tvalid's amex_gini: 0.918447\tvalid's amex_top4: 0.64781\n",
      "[98]\ttrain's binary_logloss: 0.210453\ttrain's amex: 0.803249\ttrain's amex_gini: 0.928854\ttrain's amex_top4: 0.677644\tvalid's binary_logloss: 0.224257\tvalid's amex: 0.782988\tvalid's amex_gini: 0.918502\tvalid's amex_top4: 0.647474\n",
      "[99]\ttrain's binary_logloss: 0.210262\ttrain's amex: 0.80345\ttrain's amex_gini: 0.928986\ttrain's amex_top4: 0.677914\tvalid's binary_logloss: 0.224211\tvalid's amex: 0.783303\tvalid's amex_gini: 0.918528\tvalid's amex_top4: 0.648078\n",
      "[100]\ttrain's binary_logloss: 0.210061\ttrain's amex: 0.803951\ttrain's amex_gini: 0.929124\ttrain's amex_top4: 0.678778\tvalid's binary_logloss: 0.224128\tvalid's amex: 0.783182\tvalid's amex_gini: 0.918587\tvalid's amex_top4: 0.647776\n",
      "[101]\ttrain's binary_logloss: 0.209852\ttrain's amex: 0.804023\ttrain's amex_gini: 0.929268\ttrain's amex_top4: 0.678778\tvalid's binary_logloss: 0.22402\tvalid's amex: 0.783372\tvalid's amex_gini: 0.918665\tvalid's amex_top4: 0.648078\n",
      "[102]\ttrain's binary_logloss: 0.209669\ttrain's amex: 0.804146\ttrain's amex_gini: 0.929401\ttrain's amex_top4: 0.678891\tvalid's binary_logloss: 0.223996\tvalid's amex: 0.78338\tvalid's amex_gini: 0.918681\tvalid's amex_top4: 0.648078\n",
      "[103]\ttrain's binary_logloss: 0.20944\ttrain's amex: 0.804383\ttrain's amex_gini: 0.929572\ttrain's amex_top4: 0.679194\tvalid's binary_logloss: 0.22395\tvalid's amex: 0.783409\tvalid's amex_gini: 0.918706\tvalid's amex_top4: 0.648112\n",
      "[104]\ttrain's binary_logloss: 0.209245\ttrain's amex: 0.804449\ttrain's amex_gini: 0.929703\ttrain's amex_top4: 0.679194\tvalid's binary_logloss: 0.223882\tvalid's amex: 0.783668\tvalid's amex_gini: 0.918753\tvalid's amex_top4: 0.648582\n",
      "[105]\ttrain's binary_logloss: 0.209054\ttrain's amex: 0.804615\ttrain's amex_gini: 0.929834\ttrain's amex_top4: 0.679396\tvalid's binary_logloss: 0.223818\tvalid's amex: 0.783555\tvalid's amex_gini: 0.918797\tvalid's amex_top4: 0.648314\n",
      "[106]\ttrain's binary_logloss: 0.208817\ttrain's amex: 0.804883\ttrain's amex_gini: 0.930012\ttrain's amex_top4: 0.679755\tvalid's binary_logloss: 0.223736\tvalid's amex: 0.783792\tvalid's amex_gini: 0.918867\tvalid's amex_top4: 0.648717\n",
      "[107]\ttrain's binary_logloss: 0.208623\ttrain's amex: 0.805102\ttrain's amex_gini: 0.930145\ttrain's amex_top4: 0.680058\tvalid's binary_logloss: 0.223671\tvalid's amex: 0.783763\tvalid's amex_gini: 0.91891\tvalid's amex_top4: 0.648616\n",
      "[108]\ttrain's binary_logloss: 0.208417\ttrain's amex: 0.805419\ttrain's amex_gini: 0.930285\ttrain's amex_top4: 0.680552\tvalid's binary_logloss: 0.223575\tvalid's amex: 0.783871\tvalid's amex_gini: 0.918992\tvalid's amex_top4: 0.64875\n",
      "[109]\ttrain's binary_logloss: 0.208225\ttrain's amex: 0.805655\ttrain's amex_gini: 0.930422\ttrain's amex_top4: 0.680889\tvalid's binary_logloss: 0.223485\tvalid's amex: 0.784207\tvalid's amex_gini: 0.919058\tvalid's amex_top4: 0.649355\n",
      "[110]\ttrain's binary_logloss: 0.207996\ttrain's amex: 0.805921\ttrain's amex_gini: 0.930594\ttrain's amex_top4: 0.681249\tvalid's binary_logloss: 0.223385\tvalid's amex: 0.784376\tvalid's amex_gini: 0.919129\tvalid's amex_top4: 0.649624\n",
      "[111]\ttrain's binary_logloss: 0.207809\ttrain's amex: 0.806306\ttrain's amex_gini: 0.930724\ttrain's amex_top4: 0.681889\tvalid's binary_logloss: 0.223336\tvalid's amex: 0.784224\tvalid's amex_gini: 0.919159\tvalid's amex_top4: 0.649288\n",
      "[112]\ttrain's binary_logloss: 0.207621\ttrain's amex: 0.80665\ttrain's amex_gini: 0.93085\ttrain's amex_top4: 0.68245\tvalid's binary_logloss: 0.223258\tvalid's amex: 0.784102\tvalid's amex_gini: 0.919218\tvalid's amex_top4: 0.648985\n",
      "[113]\ttrain's binary_logloss: 0.207455\ttrain's amex: 0.806875\ttrain's amex_gini: 0.930964\ttrain's amex_top4: 0.682787\tvalid's binary_logloss: 0.223218\tvalid's amex: 0.784116\tvalid's amex_gini: 0.919246\tvalid's amex_top4: 0.648985\n",
      "[114]\ttrain's binary_logloss: 0.207267\ttrain's amex: 0.807072\ttrain's amex_gini: 0.931099\ttrain's amex_top4: 0.683045\tvalid's binary_logloss: 0.223152\tvalid's amex: 0.784626\tvalid's amex_gini: 0.919292\tvalid's amex_top4: 0.64996\n",
      "[115]\ttrain's binary_logloss: 0.207076\ttrain's amex: 0.807294\ttrain's amex_gini: 0.931251\ttrain's amex_top4: 0.683337\tvalid's binary_logloss: 0.223095\tvalid's amex: 0.784833\tvalid's amex_gini: 0.919337\tvalid's amex_top4: 0.650329\n",
      "[116]\ttrain's binary_logloss: 0.206904\ttrain's amex: 0.807369\ttrain's amex_gini: 0.931367\ttrain's amex_top4: 0.683371\tvalid's binary_logloss: 0.223034\tvalid's amex: 0.785021\tvalid's amex_gini: 0.919377\tvalid's amex_top4: 0.650665\n",
      "[117]\ttrain's binary_logloss: 0.206705\ttrain's amex: 0.807774\ttrain's amex_gini: 0.931504\ttrain's amex_top4: 0.684044\tvalid's binary_logloss: 0.222958\tvalid's amex: 0.784948\tvalid's amex_gini: 0.919433\tvalid's amex_top4: 0.650464\n",
      "[118]\ttrain's binary_logloss: 0.206513\ttrain's amex: 0.807901\ttrain's amex_gini: 0.931633\ttrain's amex_top4: 0.684168\tvalid's binary_logloss: 0.222896\tvalid's amex: 0.784902\tvalid's amex_gini: 0.919475\tvalid's amex_top4: 0.650329\n",
      "[119]\ttrain's binary_logloss: 0.206336\ttrain's amex: 0.808181\ttrain's amex_gini: 0.931756\ttrain's amex_top4: 0.684606\tvalid's binary_logloss: 0.222848\tvalid's amex: 0.785322\tvalid's amex_gini: 0.919509\tvalid's amex_top4: 0.651135\n",
      "[120]\ttrain's binary_logloss: 0.20617\ttrain's amex: 0.808295\ttrain's amex_gini: 0.93186\ttrain's amex_top4: 0.684729\tvalid's binary_logloss: 0.222829\tvalid's amex: 0.785092\tvalid's amex_gini: 0.91952\tvalid's amex_top4: 0.650665\n",
      "[121]\ttrain's binary_logloss: 0.205958\ttrain's amex: 0.808381\ttrain's amex_gini: 0.932021\ttrain's amex_top4: 0.684741\tvalid's binary_logloss: 0.222797\tvalid's amex: 0.785122\tvalid's amex_gini: 0.919544\tvalid's amex_top4: 0.650699\n",
      "[122]\ttrain's binary_logloss: 0.205801\ttrain's amex: 0.808785\ttrain's amex_gini: 0.932123\ttrain's amex_top4: 0.685448\tvalid's binary_logloss: 0.222742\tvalid's amex: 0.785461\tvalid's amex_gini: 0.919584\tvalid's amex_top4: 0.651337\n",
      "[123]\ttrain's binary_logloss: 0.205643\ttrain's amex: 0.808888\ttrain's amex_gini: 0.932238\ttrain's amex_top4: 0.685538\tvalid's binary_logloss: 0.22271\tvalid's amex: 0.785488\tvalid's amex_gini: 0.919606\tvalid's amex_top4: 0.651371\n",
      "[124]\ttrain's binary_logloss: 0.205468\ttrain's amex: 0.809077\ttrain's amex_gini: 0.932359\ttrain's amex_top4: 0.685796\tvalid's binary_logloss: 0.222686\tvalid's amex: 0.785597\tvalid's amex_gini: 0.919621\tvalid's amex_top4: 0.651572\n",
      "[125]\ttrain's binary_logloss: 0.2053\ttrain's amex: 0.809163\ttrain's amex_gini: 0.932485\ttrain's amex_top4: 0.685841\tvalid's binary_logloss: 0.222693\tvalid's amex: 0.785678\tvalid's amex_gini: 0.919617\tvalid's amex_top4: 0.65174\n",
      "[126]\ttrain's binary_logloss: 0.205148\ttrain's amex: 0.809545\ttrain's amex_gini: 0.932587\ttrain's amex_top4: 0.686503\tvalid's binary_logloss: 0.222671\tvalid's amex: 0.785282\tvalid's amex_gini: 0.91963\tvalid's amex_top4: 0.650934\n",
      "[127]\ttrain's binary_logloss: 0.204997\ttrain's amex: 0.809715\ttrain's amex_gini: 0.93269\ttrain's amex_top4: 0.686739\tvalid's binary_logloss: 0.222666\tvalid's amex: 0.785535\tvalid's amex_gini: 0.919633\tvalid's amex_top4: 0.651438\n",
      "[128]\ttrain's binary_logloss: 0.204838\ttrain's amex: 0.809947\ttrain's amex_gini: 0.932806\ttrain's amex_top4: 0.687087\tvalid's binary_logloss: 0.222642\tvalid's amex: 0.785545\tvalid's amex_gini: 0.919652\tvalid's amex_top4: 0.651438\n",
      "[129]\ttrain's binary_logloss: 0.204666\ttrain's amex: 0.810339\ttrain's amex_gini: 0.932927\ttrain's amex_top4: 0.68775\tvalid's binary_logloss: 0.222612\tvalid's amex: 0.785439\tvalid's amex_gini: 0.919676\tvalid's amex_top4: 0.651203\n",
      "[130]\ttrain's binary_logloss: 0.204514\ttrain's amex: 0.810597\ttrain's amex_gini: 0.93303\ttrain's amex_top4: 0.688165\tvalid's binary_logloss: 0.222611\tvalid's amex: 0.785339\tvalid's amex_gini: 0.919677\tvalid's amex_top4: 0.651001\n",
      "[131]\ttrain's binary_logloss: 0.204375\ttrain's amex: 0.810676\ttrain's amex_gini: 0.93313\ttrain's amex_top4: 0.688221\tvalid's binary_logloss: 0.222596\tvalid's amex: 0.785342\tvalid's amex_gini: 0.919682\tvalid's amex_top4: 0.651001\n",
      "[132]\ttrain's binary_logloss: 0.204187\ttrain's amex: 0.811205\ttrain's amex_gini: 0.933257\ttrain's amex_top4: 0.689153\tvalid's binary_logloss: 0.222491\tvalid's amex: 0.785245\tvalid's amex_gini: 0.919757\tvalid's amex_top4: 0.650732\n",
      "[133]\ttrain's binary_logloss: 0.203977\ttrain's amex: 0.811272\ttrain's amex_gini: 0.933413\ttrain's amex_top4: 0.689131\tvalid's binary_logloss: 0.22244\tvalid's amex: 0.785264\tvalid's amex_gini: 0.919795\tvalid's amex_top4: 0.650732\n",
      "[134]\ttrain's binary_logloss: 0.203823\ttrain's amex: 0.811578\ttrain's amex_gini: 0.933519\ttrain's amex_top4: 0.689636\tvalid's binary_logloss: 0.222413\tvalid's amex: 0.784986\tvalid's amex_gini: 0.919811\tvalid's amex_top4: 0.650161\n",
      "[135]\ttrain's binary_logloss: 0.203666\ttrain's amex: 0.811823\ttrain's amex_gini: 0.933627\ttrain's amex_top4: 0.690018\tvalid's binary_logloss: 0.222395\tvalid's amex: 0.785178\tvalid's amex_gini: 0.919825\tvalid's amex_top4: 0.650531\n",
      "[136]\ttrain's binary_logloss: 0.203497\ttrain's amex: 0.812233\ttrain's amex_gini: 0.933751\ttrain's amex_top4: 0.690714\tvalid's binary_logloss: 0.222347\tvalid's amex: 0.785111\tvalid's amex_gini: 0.91986\tvalid's amex_top4: 0.650363\n",
      "[137]\ttrain's binary_logloss: 0.203354\ttrain's amex: 0.81247\ttrain's amex_gini: 0.933855\ttrain's amex_top4: 0.691085\tvalid's binary_logloss: 0.222318\tvalid's amex: 0.78524\tvalid's amex_gini: 0.919882\tvalid's amex_top4: 0.650598\n",
      "[138]\ttrain's binary_logloss: 0.203195\ttrain's amex: 0.812643\ttrain's amex_gini: 0.933966\ttrain's amex_top4: 0.69132\tvalid's binary_logloss: 0.222286\tvalid's amex: 0.785234\tvalid's amex_gini: 0.919903\tvalid's amex_top4: 0.650564\n",
      "[139]\ttrain's binary_logloss: 0.203037\ttrain's amex: 0.812903\ttrain's amex_gini: 0.934071\ttrain's amex_top4: 0.691736\tvalid's binary_logloss: 0.222265\tvalid's amex: 0.785459\tvalid's amex_gini: 0.919917\tvalid's amex_top4: 0.651001\n",
      "[140]\ttrain's binary_logloss: 0.20288\ttrain's amex: 0.81293\ttrain's amex_gini: 0.93418\ttrain's amex_top4: 0.69168\tvalid's binary_logloss: 0.222212\tvalid's amex: 0.785746\tvalid's amex_gini: 0.919954\tvalid's amex_top4: 0.651539\n",
      "[141]\ttrain's binary_logloss: 0.202734\ttrain's amex: 0.813326\ttrain's amex_gini: 0.934276\ttrain's amex_top4: 0.692376\tvalid's binary_logloss: 0.2222\tvalid's amex: 0.785666\tvalid's amex_gini: 0.919962\tvalid's amex_top4: 0.651371\n",
      "[142]\ttrain's binary_logloss: 0.202575\ttrain's amex: 0.813735\ttrain's amex_gini: 0.934386\ttrain's amex_top4: 0.693083\tvalid's binary_logloss: 0.222154\tvalid's amex: 0.785414\tvalid's amex_gini: 0.919994\tvalid's amex_top4: 0.650833\n",
      "[143]\ttrain's binary_logloss: 0.20242\ttrain's amex: 0.813854\ttrain's amex_gini: 0.934501\ttrain's amex_top4: 0.693207\tvalid's binary_logloss: 0.222152\tvalid's amex: 0.785582\tvalid's amex_gini: 0.919994\tvalid's amex_top4: 0.651169\n",
      "[144]\ttrain's binary_logloss: 0.202264\ttrain's amex: 0.814133\ttrain's amex_gini: 0.934609\ttrain's amex_top4: 0.693656\tvalid's binary_logloss: 0.222126\tvalid's amex: 0.785976\tvalid's amex_gini: 0.92001\tvalid's amex_top4: 0.651942\n",
      "[145]\ttrain's binary_logloss: 0.202135\ttrain's amex: 0.814488\ttrain's amex_gini: 0.934702\ttrain's amex_top4: 0.694274\tvalid's binary_logloss: 0.222133\tvalid's amex: 0.786057\tvalid's amex_gini: 0.920004\tvalid's amex_top4: 0.65211\n",
      "[146]\ttrain's binary_logloss: 0.202015\ttrain's amex: 0.814828\ttrain's amex_gini: 0.934787\ttrain's amex_top4: 0.694869\tvalid's binary_logloss: 0.222117\tvalid's amex: 0.78623\tvalid's amex_gini: 0.920014\tvalid's amex_top4: 0.652446\n",
      "[147]\ttrain's binary_logloss: 0.201811\ttrain's amex: 0.815044\ttrain's amex_gini: 0.934938\ttrain's amex_top4: 0.695149\tvalid's binary_logloss: 0.222144\tvalid's amex: 0.785968\tvalid's amex_gini: 0.919995\tvalid's amex_top4: 0.651942\n",
      "[148]\ttrain's binary_logloss: 0.201633\ttrain's amex: 0.815276\ttrain's amex_gini: 0.935065\ttrain's amex_top4: 0.695486\tvalid's binary_logloss: 0.222145\tvalid's amex: 0.786169\tvalid's amex_gini: 0.919993\tvalid's amex_top4: 0.652345\n",
      "[149]\ttrain's binary_logloss: 0.201502\ttrain's amex: 0.815427\ttrain's amex_gini: 0.935154\ttrain's amex_top4: 0.6957\tvalid's binary_logloss: 0.222158\tvalid's amex: 0.786196\tvalid's amex_gini: 0.91998\tvalid's amex_top4: 0.652412\n",
      "[150]\ttrain's binary_logloss: 0.201326\ttrain's amex: 0.815502\ttrain's amex_gini: 0.935282\ttrain's amex_top4: 0.695722\tvalid's binary_logloss: 0.222135\tvalid's amex: 0.786235\tvalid's amex_gini: 0.91999\tvalid's amex_top4: 0.652479\n",
      "[151]\ttrain's binary_logloss: 0.201185\ttrain's amex: 0.815837\ttrain's amex_gini: 0.935378\ttrain's amex_top4: 0.696295\tvalid's binary_logloss: 0.222111\tvalid's amex: 0.78621\tvalid's amex_gini: 0.920008\tvalid's amex_top4: 0.652412\n",
      "[152]\ttrain's binary_logloss: 0.201054\ttrain's amex: 0.816174\ttrain's amex_gini: 0.93547\ttrain's amex_top4: 0.696879\tvalid's binary_logloss: 0.22211\tvalid's amex: 0.786059\tvalid's amex_gini: 0.920009\tvalid's amex_top4: 0.65211\n",
      "[153]\ttrain's binary_logloss: 0.200902\ttrain's amex: 0.81638\ttrain's amex_gini: 0.935578\ttrain's amex_top4: 0.697182\tvalid's binary_logloss: 0.22209\tvalid's amex: 0.786266\tvalid's amex_gini: 0.92002\tvalid's amex_top4: 0.652513\n",
      "[154]\ttrain's binary_logloss: 0.200773\ttrain's amex: 0.816448\ttrain's amex_gini: 0.93567\ttrain's amex_top4: 0.697227\tvalid's binary_logloss: 0.222111\tvalid's amex: 0.786057\tvalid's amex_gini: 0.920004\tvalid's amex_top4: 0.65211\n",
      "[155]\ttrain's binary_logloss: 0.200616\ttrain's amex: 0.816733\ttrain's amex_gini: 0.935779\ttrain's amex_top4: 0.697687\tvalid's binary_logloss: 0.222079\tvalid's amex: 0.785966\tvalid's amex_gini: 0.920025\tvalid's amex_top4: 0.651908\n",
      "[156]\ttrain's binary_logloss: 0.200462\ttrain's amex: 0.816858\ttrain's amex_gini: 0.935895\ttrain's amex_top4: 0.697822\tvalid's binary_logloss: 0.222103\tvalid's amex: 0.786174\tvalid's amex_gini: 0.920004\tvalid's amex_top4: 0.652345\n",
      "[157]\ttrain's binary_logloss: 0.200303\ttrain's amex: 0.816995\ttrain's amex_gini: 0.936\ttrain's amex_top4: 0.69799\tvalid's binary_logloss: 0.222076\tvalid's amex: 0.786249\tvalid's amex_gini: 0.920019\tvalid's amex_top4: 0.652479\n",
      "[158]\ttrain's binary_logloss: 0.200181\ttrain's amex: 0.817224\ttrain's amex_gini: 0.936087\ttrain's amex_top4: 0.698361\tvalid's binary_logloss: 0.22206\tvalid's amex: 0.78644\tvalid's amex_gini: 0.920031\tvalid's amex_top4: 0.652849\n",
      "[159]\ttrain's binary_logloss: 0.200043\ttrain's amex: 0.817315\ttrain's amex_gini: 0.936179\ttrain's amex_top4: 0.69845\tvalid's binary_logloss: 0.222093\tvalid's amex: 0.786408\tvalid's amex_gini: 0.920001\tvalid's amex_top4: 0.652815\n",
      "[160]\ttrain's binary_logloss: 0.199889\ttrain's amex: 0.817432\ttrain's amex_gini: 0.93629\ttrain's amex_top4: 0.698574\tvalid's binary_logloss: 0.222089\tvalid's amex: 0.786458\tvalid's amex_gini: 0.92\tvalid's amex_top4: 0.652916\n",
      "[161]\ttrain's binary_logloss: 0.199756\ttrain's amex: 0.81766\ttrain's amex_gini: 0.936388\ttrain's amex_top4: 0.698933\tvalid's binary_logloss: 0.222077\tvalid's amex: 0.786429\tvalid's amex_gini: 0.920009\tvalid's amex_top4: 0.652849\n",
      "[162]\ttrain's binary_logloss: 0.199635\ttrain's amex: 0.817786\ttrain's amex_gini: 0.936471\ttrain's amex_top4: 0.699102\tvalid's binary_logloss: 0.222057\tvalid's amex: 0.786839\tvalid's amex_gini: 0.920024\tvalid's amex_top4: 0.653655\n",
      "[163]\ttrain's binary_logloss: 0.199515\ttrain's amex: 0.817987\ttrain's amex_gini: 0.936558\ttrain's amex_top4: 0.699416\tvalid's binary_logloss: 0.222053\tvalid's amex: 0.786858\tvalid's amex_gini: 0.920028\tvalid's amex_top4: 0.653689\n",
      "[164]\ttrain's binary_logloss: 0.199358\ttrain's amex: 0.818159\ttrain's amex_gini: 0.936666\ttrain's amex_top4: 0.699652\tvalid's binary_logloss: 0.222048\tvalid's amex: 0.78686\tvalid's amex_gini: 0.920031\tvalid's amex_top4: 0.653689\n",
      "[165]\ttrain's binary_logloss: 0.199225\ttrain's amex: 0.818302\ttrain's amex_gini: 0.936761\ttrain's amex_top4: 0.699843\tvalid's binary_logloss: 0.222054\tvalid's amex: 0.786957\tvalid's amex_gini: 0.920025\tvalid's amex_top4: 0.65389\n",
      "[166]\ttrain's binary_logloss: 0.199065\ttrain's amex: 0.818395\ttrain's amex_gini: 0.936879\ttrain's amex_top4: 0.69991\tvalid's binary_logloss: 0.222064\tvalid's amex: 0.786869\tvalid's amex_gini: 0.920016\tvalid's amex_top4: 0.653722\n",
      "[167]\ttrain's binary_logloss: 0.19892\ttrain's amex: 0.818514\ttrain's amex_gini: 0.936982\ttrain's amex_top4: 0.700045\tvalid's binary_logloss: 0.222084\tvalid's amex: 0.786844\tvalid's amex_gini: 0.92\tvalid's amex_top4: 0.653689\n",
      "[168]\ttrain's binary_logloss: 0.198787\ttrain's amex: 0.818677\ttrain's amex_gini: 0.937074\ttrain's amex_top4: 0.700281\tvalid's binary_logloss: 0.222096\tvalid's amex: 0.786824\tvalid's amex_gini: 0.919993\tvalid's amex_top4: 0.653655\n",
      "[169]\ttrain's binary_logloss: 0.198638\ttrain's amex: 0.819069\ttrain's amex_gini: 0.937173\ttrain's amex_top4: 0.700966\tvalid's binary_logloss: 0.222087\tvalid's amex: 0.786593\tvalid's amex_gini: 0.920001\tvalid's amex_top4: 0.653185\n",
      "[170]\ttrain's binary_logloss: 0.198531\ttrain's amex: 0.819395\ttrain's amex_gini: 0.937252\ttrain's amex_top4: 0.701538\tvalid's binary_logloss: 0.2221\tvalid's amex: 0.786588\tvalid's amex_gini: 0.919991\tvalid's amex_top4: 0.653185\n",
      "[171]\ttrain's binary_logloss: 0.198396\ttrain's amex: 0.819471\ttrain's amex_gini: 0.937336\ttrain's amex_top4: 0.701606\tvalid's binary_logloss: 0.222088\tvalid's amex: 0.786423\tvalid's amex_gini: 0.919997\tvalid's amex_top4: 0.652849\n",
      "[172]\ttrain's binary_logloss: 0.198232\ttrain's amex: 0.819678\ttrain's amex_gini: 0.937459\ttrain's amex_top4: 0.701898\tvalid's binary_logloss: 0.222074\tvalid's amex: 0.786511\tvalid's amex_gini: 0.920006\tvalid's amex_top4: 0.653017\n",
      "[173]\ttrain's binary_logloss: 0.198099\ttrain's amex: 0.820007\ttrain's amex_gini: 0.937555\ttrain's amex_top4: 0.702459\tvalid's binary_logloss: 0.222079\tvalid's amex: 0.78651\tvalid's amex_gini: 0.920003\tvalid's amex_top4: 0.653017\n",
      "[174]\ttrain's binary_logloss: 0.197984\ttrain's amex: 0.820205\ttrain's amex_gini: 0.937637\ttrain's amex_top4: 0.702773\tvalid's binary_logloss: 0.222065\tvalid's amex: 0.786648\tvalid's amex_gini: 0.920011\tvalid's amex_top4: 0.653285\n",
      "[175]\ttrain's binary_logloss: 0.197823\ttrain's amex: 0.820298\ttrain's amex_gini: 0.937755\ttrain's amex_top4: 0.702841\tvalid's binary_logloss: 0.222057\tvalid's amex: 0.786601\tvalid's amex_gini: 0.920018\tvalid's amex_top4: 0.653185\n",
      "[176]\ttrain's binary_logloss: 0.19769\ttrain's amex: 0.820481\ttrain's amex_gini: 0.937852\ttrain's amex_top4: 0.70311\tvalid's binary_logloss: 0.222052\tvalid's amex: 0.78657\tvalid's amex_gini: 0.920022\tvalid's amex_top4: 0.653117\n",
      "[177]\ttrain's binary_logloss: 0.197581\ttrain's amex: 0.820755\ttrain's amex_gini: 0.937929\ttrain's amex_top4: 0.703582\tvalid's binary_logloss: 0.222048\tvalid's amex: 0.786588\tvalid's amex_gini: 0.920024\tvalid's amex_top4: 0.653151\n",
      "[178]\ttrain's binary_logloss: 0.197437\ttrain's amex: 0.821002\ttrain's amex_gini: 0.938029\ttrain's amex_top4: 0.703975\tvalid's binary_logloss: 0.222016\tvalid's amex: 0.786549\tvalid's amex_gini: 0.920049\tvalid's amex_top4: 0.65305\n",
      "[179]\ttrain's binary_logloss: 0.197282\ttrain's amex: 0.821252\ttrain's amex_gini: 0.938137\ttrain's amex_top4: 0.704368\tvalid's binary_logloss: 0.221969\tvalid's amex: 0.786735\tvalid's amex_gini: 0.920084\tvalid's amex_top4: 0.653386\n",
      "[180]\ttrain's binary_logloss: 0.197144\ttrain's amex: 0.821487\ttrain's amex_gini: 0.938224\ttrain's amex_top4: 0.70475\tvalid's binary_logloss: 0.222001\tvalid's amex: 0.786825\tvalid's amex_gini: 0.920062\tvalid's amex_top4: 0.653588\n",
      "[181]\ttrain's binary_logloss: 0.197008\ttrain's amex: 0.82174\ttrain's amex_gini: 0.938314\ttrain's amex_top4: 0.705165\tvalid's binary_logloss: 0.221992\tvalid's amex: 0.786878\tvalid's amex_gini: 0.920068\tvalid's amex_top4: 0.653689\n",
      "[182]\ttrain's binary_logloss: 0.196895\ttrain's amex: 0.821905\ttrain's amex_gini: 0.938399\ttrain's amex_top4: 0.705412\tvalid's binary_logloss: 0.221994\tvalid's amex: 0.786877\tvalid's amex_gini: 0.920065\tvalid's amex_top4: 0.653689\n",
      "[183]\ttrain's binary_logloss: 0.196772\ttrain's amex: 0.822157\ttrain's amex_gini: 0.938487\ttrain's amex_top4: 0.705828\tvalid's binary_logloss: 0.222013\tvalid's amex: 0.786685\tvalid's amex_gini: 0.920051\tvalid's amex_top4: 0.653319\n",
      "[184]\ttrain's binary_logloss: 0.19663\ttrain's amex: 0.82251\ttrain's amex_gini: 0.938575\ttrain's amex_top4: 0.706445\tvalid's binary_logloss: 0.221968\tvalid's amex: 0.786619\tvalid's amex_gini: 0.920088\tvalid's amex_top4: 0.653151\n",
      "[185]\ttrain's binary_logloss: 0.196503\ttrain's amex: 0.822584\ttrain's amex_gini: 0.938667\ttrain's amex_top4: 0.706501\tvalid's binary_logloss: 0.221975\tvalid's amex: 0.786567\tvalid's amex_gini: 0.920083\tvalid's amex_top4: 0.65305\n",
      "[186]\ttrain's binary_logloss: 0.196378\ttrain's amex: 0.822674\ttrain's amex_gini: 0.938757\ttrain's amex_top4: 0.706591\tvalid's binary_logloss: 0.221981\tvalid's amex: 0.786564\tvalid's amex_gini: 0.920079\tvalid's amex_top4: 0.65305\n",
      "[187]\ttrain's binary_logloss: 0.196224\ttrain's amex: 0.822837\ttrain's amex_gini: 0.93887\ttrain's amex_top4: 0.706804\tvalid's binary_logloss: 0.221975\tvalid's amex: 0.7867\tvalid's amex_gini: 0.920082\tvalid's amex_top4: 0.653319\n",
      "[188]\ttrain's binary_logloss: 0.19611\ttrain's amex: 0.823121\ttrain's amex_gini: 0.938955\ttrain's amex_top4: 0.707287\tvalid's binary_logloss: 0.221998\tvalid's amex: 0.78654\tvalid's amex_gini: 0.920064\tvalid's amex_top4: 0.653017\n",
      "[189]\ttrain's binary_logloss: 0.195995\ttrain's amex: 0.82332\ttrain's amex_gini: 0.939038\ttrain's amex_top4: 0.707602\tvalid's binary_logloss: 0.221986\tvalid's amex: 0.786545\tvalid's amex_gini: 0.920073\tvalid's amex_top4: 0.653017\n",
      "[190]\ttrain's binary_logloss: 0.195848\ttrain's amex: 0.823594\ttrain's amex_gini: 0.939137\ttrain's amex_top4: 0.708051\tvalid's binary_logloss: 0.221938\tvalid's amex: 0.786529\tvalid's amex_gini: 0.920108\tvalid's amex_top4: 0.652949\n",
      "[191]\ttrain's binary_logloss: 0.195728\ttrain's amex: 0.823783\ttrain's amex_gini: 0.939223\ttrain's amex_top4: 0.708343\tvalid's binary_logloss: 0.221933\tvalid's amex: 0.786581\tvalid's amex_gini: 0.920111\tvalid's amex_top4: 0.65305\n",
      "[192]\ttrain's binary_logloss: 0.19562\ttrain's amex: 0.823963\ttrain's amex_gini: 0.939304\ttrain's amex_top4: 0.708623\tvalid's binary_logloss: 0.221955\tvalid's amex: 0.786625\tvalid's amex_gini: 0.920098\tvalid's amex_top4: 0.653151\n",
      "[193]\ttrain's binary_logloss: 0.195508\ttrain's amex: 0.824147\ttrain's amex_gini: 0.939378\ttrain's amex_top4: 0.708915\tvalid's binary_logloss: 0.221939\tvalid's amex: 0.786647\tvalid's amex_gini: 0.92011\tvalid's amex_top4: 0.653185\n",
      "[194]\ttrain's binary_logloss: 0.195375\ttrain's amex: 0.8243\ttrain's amex_gini: 0.93946\ttrain's amex_top4: 0.70914\tvalid's binary_logloss: 0.221938\tvalid's amex: 0.786697\tvalid's amex_gini: 0.920109\tvalid's amex_top4: 0.653285\n",
      "[195]\ttrain's binary_logloss: 0.19525\ttrain's amex: 0.824617\ttrain's amex_gini: 0.939544\ttrain's amex_top4: 0.70969\tvalid's binary_logloss: 0.221945\tvalid's amex: 0.786643\tvalid's amex_gini: 0.920101\tvalid's amex_top4: 0.653185\n",
      "[196]\ttrain's binary_logloss: 0.195144\ttrain's amex: 0.824767\ttrain's amex_gini: 0.939619\ttrain's amex_top4: 0.709915\tvalid's binary_logloss: 0.221945\tvalid's amex: 0.786643\tvalid's amex_gini: 0.920101\tvalid's amex_top4: 0.653185\n",
      "[197]\ttrain's binary_logloss: 0.195013\ttrain's amex: 0.824883\ttrain's amex_gini: 0.939717\ttrain's amex_top4: 0.710049\tvalid's binary_logloss: 0.221958\tvalid's amex: 0.786604\tvalid's amex_gini: 0.920091\tvalid's amex_top4: 0.653117\n",
      "[198]\ttrain's binary_logloss: 0.194889\ttrain's amex: 0.825041\ttrain's amex_gini: 0.939807\ttrain's amex_top4: 0.710274\tvalid's binary_logloss: 0.221972\tvalid's amex: 0.786549\tvalid's amex_gini: 0.920081\tvalid's amex_top4: 0.653017\n",
      "[199]\ttrain's binary_logloss: 0.19485\ttrain's amex: 0.825104\ttrain's amex_gini: 0.939878\ttrain's amex_top4: 0.71033\tvalid's binary_logloss: 0.222136\tvalid's amex: 0.786324\tvalid's amex_gini: 0.920035\tvalid's amex_top4: 0.652614\n",
      "[200]\ttrain's binary_logloss: 0.194709\ttrain's amex: 0.82518\ttrain's amex_gini: 0.939962\ttrain's amex_top4: 0.710397\tvalid's binary_logloss: 0.222224\tvalid's amex: 0.786378\tvalid's amex_gini: 0.919975\tvalid's amex_top4: 0.652782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/06/21 11:43:58 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID a4afb732fa744b81b8e3163f9af307b0. Failed operations: [MlflowException(\"Duplicate parameter keys have been submitted: [\\'num_boost_round\\']. Please ensure the request contains only one param value per param key.\")]')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 40s, sys: 12.9 s, total: 11min 52s\n",
      "Wall time: 5min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import mlflow\n",
    "from lightgbm import LGBMClassifier\n",
    "from evaluation import feval_amex, feval_amex_gini, feval_amex_top4\n",
    "import tempfile\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "mlflow.lightgbm.autolog()\n",
    "experiment_id = mlflow.get_experiment_by_name('v2_aggregated.ipynb').experiment_id\n",
    "with mlflow.start_run(experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    print('run_id', run_id)\n",
    "\n",
    "    # store things required for prediction\n",
    "    with tempfile.TemporaryDirectory() as p:\n",
    "        prediction_artifacts = {\n",
    "            'encs': encs,\n",
    "            'feature_columns': feature_columns,\n",
    "            # TODO: pack a spark dataframe to X transformer here so simplify prediction\n",
    "        }\n",
    "        with open(os.path.join(p, 'prediction_artifacts.pickle'), 'wb') as f:\n",
    "            pickle.dump(prediction_artifacts, f)\n",
    "        mlflow.log_artifacts(p)\n",
    "\n",
    "    #  training\n",
    "    m = LGBMClassifier(\n",
    "        num_boost_round=200,\n",
    "    ).fit(\n",
    "        X=X_train, y=y_train, categorical_feature=encs.columns_encoded,\n",
    "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "        eval_names=['train', 'valid'],\n",
    "        eval_metric=[feval_amex, feval_amex_gini, feval_amex_top4],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: Dio.netty.tryReflectionSetAccessible\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/06/22 03:20:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# run these if kernel dies due to OOM\n",
    "\n",
    "import mlflow\n",
    "import tempfile\n",
    "import pickle\n",
    "from spark_utils import get_spark_session\n",
    "\n",
    "spark = get_spark_session()\n",
    "run_id = 'a4afb732fa744b81b8e3163f9af307b0'\n",
    "\n",
    "\n",
    "loaded_model = mlflow.lightgbm.load_model(f'runs:/{run_id}/model')\n",
    "\n",
    "with tempfile.TemporaryDirectory() as p:\n",
    "    p = mlflow.artifacts.download_artifacts(\n",
    "        run_id=run_id, artifact_path='prediction_artifacts.pickle', dst_path=p)\n",
    "    with open(p, 'rb') as f:\n",
    "        prediction_artifacts = pickle.load(f)\n",
    "\n",
    "# print(loaded_model, prediction_artifacts)\n",
    "\n",
    "encs = prediction_artifacts['encs']\n",
    "feature_columns = prediction_artifacts['feature_columns']\n",
    "m = loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:================================================>        (16 + 3) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 [0, 18718, 37436, 56154, 74872, 93590, 112308, 131026, 149744, 168462, 187180, 205898, 224616, 243334, 262052, 280770, 299488, 318206, 336924]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from format_data import PREDICTION_VARIABLE\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "test_data = spark.read.parquet('data_transformed/amex-default-prediction/test_data_aggregated')\n",
    "test_batch_size = 458913\n",
    "\n",
    "test_data = test_data.withColumn(\n",
    "    'batch_num', F.floor(F.monotonically_increasing_id()/F.lit(test_batch_size)))\n",
    "test_batch_indices = [\n",
    "    row['batch_num'] for row in test_data.select('batch_num').distinct().collect()]\n",
    "print(len(test_batch_indices), test_batch_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/22 03:20:27 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48694, 931)\n",
      "[1/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48701, 931)\n",
      "[2/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48686, 931)\n",
      "[3/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48698, 931)\n",
      "[4/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48678, 931)\n",
      "[5/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48676, 931)\n",
      "[6/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48680, 931)\n",
      "[7/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48662, 931)\n",
      "[8/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48667, 931)\n",
      "[9/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48654, 931)\n",
      "[10/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48666, 931)\n",
      "[11/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48655, 931)\n",
      "[12/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48657, 931)\n",
      "[13/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48660, 931)\n",
      "[14/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48638, 931)\n",
      "[15/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48638, 931)\n",
      "[16/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48635, 931)\n",
      "[17/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48632, 931)\n",
      "[18/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48644, 931)\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74.2M/74.2M [00:01<00:00, 41.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to American Express - Default PredictionCPU times: user 34.4 s, sys: 12 s, total: 46.4 s\n",
      "Wall time: 5min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pred_test_l = []\n",
    "for i, test_batch_index in enumerate(test_batch_indices):\n",
    "    print(f'[{i}/{len(test_batch_indices)}]')\n",
    "    test_pdf = encs.transform(\n",
    "        spark=spark, df=test_data.filter(F.col('batch_num') == test_batch_index)\n",
    "    ).toPandas()\n",
    "\n",
    "    X_test = test_pdf[feature_columns].reset_index(drop=True).astype(float)\n",
    "    print(X_test.shape)\n",
    "\n",
    "    pred_test = pd.DataFrame({\n",
    "        'customer_ID': test_pdf['customer_ID'],\n",
    "        PREDICTION_VARIABLE: m.predict(X_test, raw_score=True),\n",
    "         \n",
    "    })\n",
    "    pred_test_l.append(pred_test)\n",
    "\n",
    "pred_test = pd.concat(pred_test_l, axis=0)\n",
    "pred_test.head()\n",
    "pred_test.to_csv(f'{run_id}.csv', index=False)\n",
    "os.system(f'kaggle competitions submit -c amex-default-prediction -f {run_id}.csv -m \"{run_id}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/22 03:26:20 WARN TaskSetManager: Stage 23 contains a task of very large size (8582 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/06/22 03:26:21 WARN TaskSetManager: Stage 26 contains a task of very large size (8582 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(924621, 924621)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_df = spark.createDataFrame(pred_test)\n",
    "assert pred_test_df.count() == pred_test_df.select('customer_ID').distinct().count()\n",
    "\n",
    "sample_submission = spark.read.parquet('data/amex-default-prediction/sample_submission')\n",
    "assert pred_test_df.count() == pred_test_df.join(sample_submission, on='customer_ID', how='inner').count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
